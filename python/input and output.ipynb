{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 键盘敲入参数 `input()`\n",
    "\n",
    "当运行到`input()`函数时，程序会暂停运行，同时等待键盘输入，输入完之后，按下回车键，此时**传入一个字符串类型的参数**。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, you can call me guagua\n"
     ]
    }
   ],
   "source": [
    "# type your name in the input window\n",
    "name = input('Please enter your name')\n",
    "\n",
    "print(f'Hey, you can call me {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 <class 'str'> 2 <class 'str'>\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "a = input('a is')\n",
    "b = input('b is')\n",
    "print(a,type(a),b,type(b))\n",
    "print(int(a) + int(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文件输入输出 `open()`\n",
    "计算机内核（kernel）对文件的处理相对比较复杂，涉及到内核模式、虚拟文件系统、锁和指针等一系列概念。\n",
    "\n",
    "用`open(file, mode='r', buffering=- 1, encoding=None, errors=None, newline=None, closefd=True, opener=None)`函数拿到文件的指针。其中：\n",
    "- **file**指定文件的local path.\n",
    "- **mode**指定读写模式，如果是 'r' 表示读取，如果是'w' 则表示写入，当然也可以用 'rw' ，表示读写都要。'a' 则是一个不太常用（但也很有用）的参数，表示追加（append），这样打开的文件，如果需要写入，会从原始文件的最末尾开始写入。\n",
    "  ```text\n",
    "  'r':open for reading (default)\n",
    "  'w':open for writing, truncating the file first\n",
    "  'x':open for exclusive creation, failing if the file already exists\n",
    "  'a':open for writing, appending to the end of file if it exists\n",
    "  '+':open for updating (reading and writing)\n",
    "  'b':binary mode\n",
    "  't':text mode(default)\n",
    "  ```\n",
    "- **encoding** 指定文件的编码方式，用于编码和解码文件。只能用在text模式中。\n",
    "- **errors** is an optional string that specifies how encoding and decoding errors are to be handled—this cannot be used in binary mode.\n",
    " - 'strict' to raise a ValueError exception if there is an encoding error. The default value of None has the same effect.\n",
    " - 'ignore' ignores errors. Note that ignoring encoding errors can lead to data loss.\n",
    " - 'replace' causes a replacement marker (such as '?') to be inserted where there is malformed data.\n",
    " - 'surrogateescape' will represent any incorrect bytes as low surrogate code units ranging from U+DC80 to U+DCFF. These surrogate code units will then be turned back into the same bytes when the surrogateescape error handler is used when writing data. This is useful for processing files in an unknown encoding.\n",
    " - 'xmlcharrefreplace' is only supported when writing to a file. Characters not supported by the encoding are replaced with the appropriate XML character reference &#nnn;.\n",
    " - 'backslashreplace' replaces malformed data by Python’s backslashed escape sequences.\n",
    " - 'namereplace' (also only supported when writing) replaces unsupported characters with \\N{...} escape sequences.\n",
    "- **newline** determines how to parse newline characters from the stream. It can be None, '', '\\n', '\\r', and '\\r\\n'.\n",
    "# `read(size)`\n",
    "通过 read() 函数，来读取文件的全部内容。代码 `text = fin.read()` ，即表示把文件所有内容读取到内存中，并赋值给变量 text。这么做自然也是有利有弊： \n",
    " - 优点是方便，接下来我们可以很方便地调用 parse 函数进行分析； \n",
    " - 缺点是如果文件过大，一次性读取可能造成内存崩溃。\n",
    "\n",
    "如果文件过大，可以给 read 指定参数 size ，用来表示读取的最大长度。\n",
    "# `readline()`\n",
    "逐行读取。如果每行之间没有关联，这种做法也可以降低内存的压力。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('in.txt', 'r') as fin:\n",
    "    text = fin.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `write(string)`写入文件\n",
    "Writes the contents of string to the file, returning the number of characters written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('in.txt', 'w') as f:\n",
    "    f.write('This is a test\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON文件读取\n",
    "\n",
    "`json.dump()` the json.dump() function is used to serialize Python objects into a JSON formatted string and write it to a file-like object.\n",
    "\n",
    "`json.dumps()` the json.dumps() function is used to serialize Python objects into a JSON formatted string. Unlike json.dump(), which writes the JSON data to a file-like object, json.dumps() returns the JSON string as a result.\n",
    "\n",
    "`json.load()` the json.load() function is used to deserialize a JSON formatted string or file-like object into a Python object. \n",
    "\n",
    "`json.loads()` the json.loads() function is used to deserialize a JSON formatted string into a Python object. It is similar to the json.load() function, but instead of reading from a file-like object, json.loads() directly accepts a JSON string as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = {\n",
    "    \"name\": \"John\",\n",
    "    \"age\": 30,\n",
    "    \"city\": \"New York\"\n",
    "}\n",
    "\n",
    "with open(\"data.json\", \"w\") as file:\n",
    "    json.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = {\n",
    "    \"name\": \"John\",\n",
    "    \"age\": 30,\n",
    "    \"city\": \"New York\"\n",
    "}\n",
    "\n",
    "json_string = json.dumps(data)\n",
    "print(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John', 'age': 30, 'city': 'New York'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John', 'age': 30, 'city': 'New York'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_string = '{\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}'\n",
    "data = json.loads(json_string)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 思考题\n",
    "1. 你能否把 NLP 例子中的 word count 实现一遍？不过这次，in.txt 可能非常非常大（意味着你不能一次读取到内存中），而 output.txt 不会很大（意味着重复的单词数量很多）。提示：你可能需要每次读取一定长度的字符串，进行处理，然后再读取下一次的。但是如果单纯按照长度划分，你可能会把一个单词隔断开，所以需要细心处理这种边界情况。\n",
    "2. 你应该使用过类似百度网盘、Dropbox 等网盘，但是它们可能空间有限（比如 5GB）。如果有一天，你计划把家里的 100GB 数据传送到公司，可惜你没带 U 盘，于是你想了一个主意： 每次从家里向 Dropbox 网盘写入不超过 5GB 的数据，而公司电脑一旦侦测到新数据，就立即拷贝到本地，然后删除网盘上的数据。等家里电脑侦测到本次数据全部传入公司电脑后，再进行下一次写入，直到所有数据都传输过去。 根据这个想法，你计划在家写一个 server.py，在公司写一个 client.py 来实现这个需求。 提示：我们假设每个文件都不超过 5GB。\n",
    "   你可以通过写入一个控制文件（config.json）来同步状态。不过，要小心设计状态，这里有可能产生 race condition。\n",
    "   你也可以通过直接侦测文件是否产生，或者是否被删除来同步状态，这是最简单的做法。\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Python's regular expressions, the \\w pattern is a shortha\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "\n",
    "import re\n",
    "\t\n",
    "# readline版本的parse，练习1\n",
    "# 处理文本\n",
    "def parse_readline(infile):\n",
    "\t# 生成单词和词频的字典\n",
    "\tword_cnt = {}\n",
    "\twhile True:\n",
    "\t\ttext = infile.readline()\n",
    "\t\tif not text:\n",
    "\t\t\tbreak\n",
    "\t\tprint(text)\n",
    "\t\t# 去除标点符号和换行\n",
    "\t\ttext = re.sub(r'[^\\w ]', ' ', text)\n",
    "\t\t# 转为小写\n",
    "\t\ttext = text.lower()\n",
    "\t\t# 单词列表\n",
    "\t\tword_list = text.split(' ')\n",
    "\t\t# 去除空白单词\n",
    "\t\tword_list = filter(None, word_list)\n",
    "\t\t\n",
    "\t\tfor word in word_list:\n",
    "\t\t\tif word not in word_cnt:\n",
    "\t\t\t\tword_cnt[word] = 0\n",
    "\t\t\tword_cnt[word] += 1\n",
    "\t\t\n",
    "\t\t# 按照词频排序\n",
    "\t\tsorted_word_cnt = sorted(word_cnt.items(), key = lambda kv: kv[1], reverse = True)\n",
    "\t\treturn sorted_word_cnt\n",
    "\t\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    with open('text.txt','r') as fin:\n",
    "        word_and_freq = parse_readline(fin)\n",
    "        \n",
    "    with open('out_readline.txt','w') as fout:\n",
    "        for word, freq in word_and_freq:\n",
    "            fout.write('{} {}\\n'.format(word, freq))\n",
    "\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
